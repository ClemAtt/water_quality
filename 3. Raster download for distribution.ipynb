{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import rasterio as rio\n",
    "import earthpy.spatial as es\n",
    "import pyproj;  \n",
    "\n",
    "import urllib\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "from ipypb import track\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## home directory for downloads\n",
    "os.chdir(\"E:/University College London/O'Sullivan, Aidan - SDG6/\")\n",
    "\n",
    "## path for where dsid csvs and sites3.p file are stored\n",
    "d_path = \"./Landsat data/Distributed download/\"\n",
    "\n",
    "## path where downloaded rasters to be saved\n",
    "c1_path = \"./Landsat data/Cropped level 1 data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropper(raster, geoms, outpath):\n",
    "    \"\"\"\n",
    "    This function accepts a raster object, an interable list of geometrys (or a single geometry),\n",
    "    and a filepath to save the cropped raster to, the cropped raster is then read back in and returned.\n",
    "    \"\"\"    \n",
    "    ## As crop accepts an iterable of geoms we first put any single geoms into a list\n",
    "    if not isinstance(geoms, Iterable):\n",
    "        geoms = [geoms]\n",
    "\n",
    "    ## Next we crop the image\n",
    "    raster_crop, raster_crop_meta = es.crop_image(raster, geoms)\n",
    "\n",
    "    ## We now need to update the metadata with the spatial data\n",
    "    raster_crop_meta.update({'transform': raster_crop_meta['transform'],\n",
    "                             'height': raster_crop.shape[1],\n",
    "                             'width': raster_crop.shape[2],\n",
    "                             'nodata': raster_crop.min()}) # <- This is the 'mask' value\n",
    "    \n",
    "    with rio.open(outpath, 'w', **raster_crop_meta) as file:\n",
    "        file.write(raster_crop[0], 1)\n",
    "        \n",
    "    raster_crop = rio.open(outpath)\n",
    "    \n",
    "    return raster_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in sites data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = pd.read_pickle(\"sites4.p\")#.set_index(['sid','dt'])\n",
    "sites = sites.set_geometry('geometry_poly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter site data for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Filter sites and dates for those with scenes\n",
    "dll = sites[sites.display_id.notna()]\n",
    "\n",
    "## Filter sites for those with geometry\n",
    "dll = dll[dll.geometry_poly.notna()].set_geometry('geometry_poly')\n",
    "\n",
    "## Optional filter to remove sites with v large polygons\n",
    "dll = dll[dll.geometry_poly.area<4]\n",
    "\n",
    "len(dll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in list of scenes to download and filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of scenes to download: 931'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change dsid file to read in\n",
    "dsids = list(pd.read_csv(d_path+'dsids_17.csv')['0'])\n",
    "\n",
    "## filter for for already downloaded scenes\n",
    "dowloaded_scenes = [ i.replace('_MTL.txt','') for i in os.listdir(c1_path) if 'MTL' in i ]\n",
    "\n",
    "dsids = [ i for i in dsids if i not in dowloaded_scenes ]\n",
    "\n",
    "## filter LM05 and LT08 scenes\n",
    "dsids = [ i for i in dsids if 'LM05' not in i ]\n",
    "dsids = [ i for i in dsids if 'LT08' not in i ]\n",
    "dsids = [ i for i in dsids if 'LO08' not in i ]\n",
    "\n",
    "## filter for whether in updated sites data\n",
    "dll_dsids = dll.reset_index().display_id\n",
    "dll_dsids = [ i for i in dll_dsids.unique() if i is not np.nan ]\n",
    "\n",
    "dsids = [ i for i in dsids if i in dll_dsids ]\n",
    "\n",
    "\n",
    "f'Number of scenes to download: {len(dsids)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in exceptions lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change directory for\n",
    "crop_exceptions = [pd.read_csv(d_path+'crop_exceptions.csv')]\n",
    "meta_exceptions = [pd.read_csv(d_path+'meta_exceptions.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through scene list and sites to download and crop rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"931\" value=\"145\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>16%</strong></span>\n",
       "<span class=\"Iteration-label\">144/931</span>\n",
       "<span class=\"Time-label\">[01:57:13<00:38, 48.51s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [█████████###################################################] 145/931 [01:57:13<00:38, 48.51s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene meta not available LE07_L1GT_118209_20000614_20170211_01_T2\n",
      "Scene meta not available LE07_L1GT_117210_20050605_20170114_01_T2\n",
      "Scene meta not available LE07_L1GT_117209_20050605_20170115_01_T2\n",
      "Scene meta not available LE07_L1GT_116209_20031031_20170123_01_T2\n",
      "Crop exception for LC08_L1TP_019035_20131026_20170308_01_T1 BQA\n",
      "Scene meta not available LE07_L1GT_119209_20020627_20170130_01_T2\n",
      "Scene meta not available LE07_L1GT_117209_20020613_20170129_01_T2\n",
      "Scene meta not available LE07_L1GT_116210_20100612_20161214_01_T2\n"
     ]
    }
   ],
   "source": [
    "## set crop buffer distance (300m)\n",
    "bbox_bufd = 300   # to calculate in degrees 360*300/(40000*1000)\n",
    "\n",
    "## create bands and metadata lists\n",
    "bands_5 = ['B1','B2','B3','B4','B5','BQA','B6']\n",
    "bands_7 = ['B1','B2','B3','B4','B5','BQA','B6_VCID_1','B6_VCID_2']\n",
    "bands_8 = ['B2','B3','B4','B5','BQA','B10','B11']\n",
    "\n",
    "meta_file_5 = ['MTL','ANG']\n",
    "meta_file_7 = ['MTL','ANG','GCP']\n",
    "meta_file_8 = ['MTL','ANG']\n",
    "\n",
    "for dsid in track(dsids):\n",
    "    \n",
    "    #~~~~ TIF download ~~~~#\n",
    "    \n",
    "    sitesdl = dll[dll.display_id==dsid]\n",
    "    \n",
    "    ## create iterable based on platform and bands\n",
    "    if 'LT05' in dsid:\n",
    "        zip_list = list(zip(bands_5,[dsid]*len(bands_5)))               \n",
    "    elif 'LE07' in dsid:\n",
    "        zip_list = list(zip(bands_7,[dsid]*len(bands_7)))\n",
    "    elif 'LC08' in dsid:\n",
    "        zip_list = list(zip(bands_8,[dsid]*len(bands_8)))\n",
    "    \n",
    "    ## open scene for each band in turn\n",
    "    for band,dsid in zip_list:\n",
    "\n",
    "        ## create url elements\n",
    "        platform = dsid[0:4]\n",
    "        key = dsid[10:13]+'/'+dsid[13:16]\n",
    "\n",
    "        ## TIF construct source url\n",
    "        filepath = f'https://storage.googleapis.com/gcp-public-data-landsat/{platform}/01/{key}/{dsid}/{dsid}_{band}.TIF'\n",
    "\n",
    "        with rio.open(filepath) as src:\n",
    "            \n",
    "            ## loop through sites with that scene\n",
    "            for sid in sitesdl.index.get_level_values(0):\n",
    "                \n",
    "                ## subset site list for site\n",
    "                sitedl = sitesdl.loc[sid,:]\n",
    "\n",
    "                ## setup polygon for cropping\n",
    "                polygon_bbox = sitedl.envelope.to_crs(src.crs) ## create bounding box and change to source crs                     \n",
    "                polygon_bbox = polygon_bbox.buffer(bbox_bufd) ## buffer bounding box by duffer distance e.g. 300m\n",
    "                polygon_geom = polygon_bbox.geometry          ## select geometry\n",
    "\n",
    "                try:\n",
    "\n",
    "                    cropped = cropper(src, polygon_geom, c1_path+sid+'__'+dsid+'_'+band+'.TIF')            \n",
    "\n",
    "                except:\n",
    "                    crop_exceptions.append(dsid+band)\n",
    "                    print(f'Crop exception for {dsid} {band}')\n",
    "\n",
    "\n",
    "            src.close()\n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "    #~~~~ metadata download ~~~~#\n",
    "    \n",
    "    ## create iterable based on platform and meta file\n",
    "    if 'LT05' in dsid:\n",
    "        mzip_list = list(zip(meta_file_5,[dsid]*len(meta_file_5)))               \n",
    "    elif 'LE07' in dsid:\n",
    "        mzip_list = list(zip(meta_file_7,[dsid]*len(meta_file_7)))  \n",
    "    elif 'LC08' in dsid:\n",
    "        mzip_list = list(zip(meta_file_8,[dsid]*len(meta_file_8)))  \n",
    "    \n",
    "    ## loop through meta dile and scenes\n",
    "    \n",
    "    for mf,dsid in mzip_list:\n",
    "\n",
    "        ## create url elements\n",
    "        platform = dsid[0:4]\n",
    "        key = dsid[10:13]+'/'+dsid[13:16]\n",
    "\n",
    "        ## Metadata construct source url\n",
    "        filepath = f'https://storage.googleapis.com/gcp-public-data-landsat/{platform}/01/{key}/{dsid}/{dsid}_{mf}.txt'\n",
    "\n",
    "        try:\n",
    "\n",
    "            ## MTL file\n",
    "            remote_file = urllib.request.urlopen(filepath).read()\n",
    "\n",
    "            local_file = open(c1_path+dsid+'_'+mf+'.txt','wb')\n",
    "            local_file.write(remote_file)\n",
    "            local_file.close()\n",
    "\n",
    "        except:\n",
    "            meta_exceptions.append(dsid)\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            print(f'Scene meta not available {dsid}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write exceptions list to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(meta_exceptions).to_csv('./Landsat data/meta_exceptions.csv')\n",
    "pd.Series(crop_exceptions).to_csv('./Landsat data/crop_exceptions.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "732-392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
