{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "from rasterio.plot import show\n",
    "import rasterio as rio\n",
    "import rasterio.features\n",
    "import rasterio.warp\n",
    "import earthpy.spatial as es\n",
    "import os\n",
    "from shapely.geometry import Polygon\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import pyproj;                                 #pyproj.set_datapath(\"C:/Users/User/Anaconda3/envs/geo/Lib/site-packages/pyproj\")\n",
    "from collections.abc import Iterable\n",
    "import time\n",
    "import math\n",
    "from ipypb import track\n",
    "import seaborn as sn\n",
    "import urllib\n",
    "import sys\n",
    "import warnings\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/User/Documents/Work/SDGs and AI/6.3.2\")\n",
    "s_path = './Landsat/Scenes/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in list of sites for download and setup metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = pd.read_pickle(\"sites2.p\")\n",
    "sites = sites.reset_index().set_index(['sid','dt'])\n",
    "sites = sites.set_geometry('geometry_poly')\n",
    "sites = sites.drop(columns=['monitoringSiteIdentifier','wbid','thematicId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"22092\" value=\"22092\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">14740/22092</span>\n",
       "<span class=\"Time-label\">[00:50<00:00, 0.00s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [████████████████████████████████████████████████████████████] 22092/22092 [00:50<00:00, 0.00s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Add in display id and aquisition date\n",
    "\n",
    "ziplist = zip(sites.index.get_level_values(0),sites.index.get_level_values(1),\n",
    "              sites.l7_scene_id,sites.l8_scene_id)\n",
    "\n",
    "for sid,dt,l7_scene_id,l8_scene_id in track(ziplist,len(sites)):\n",
    "    \n",
    "    date = dt.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if (isinstance(l7_scene_id,str)==True):\n",
    "        sc_meta7 = pickle.load(open('./Landsat/Scenes/scene_'+str(l7_scene_id)+\".p\",\"rb\"))\n",
    "        \n",
    "        sites.loc[(sid,date),'l7_display_id'] = sc_meta7[0]['displayId']\n",
    "        sites.loc[(sid,date),'l7_acquisition_dt'] = sc_meta7[0]['acquisitionDate']\n",
    "        \n",
    "        del(sc_meta7)\n",
    "\n",
    "    elif (isinstance(l8_scene_id,str)==True):\n",
    "        sc_meta8 = pickle.load(open('./Landsat/Scenes/scene_'+str(l8_scene_id)+\".p\",\"rb\"))\n",
    "        \n",
    "        sites.loc[(sid,date),'l8_display_id'] = sc_meta8[0]['displayId']\n",
    "        sites.loc[(sid,date),'l8_acquisition_dt'] = sc_meta8[0]['acquisitionDate']\n",
    "        \n",
    "        del(sc_meta8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropper(raster, geoms, outpath):\n",
    "    \"\"\"\n",
    "    This function accepts a raster object, an interable list of geometrys (or a single geometry),\n",
    "    and a filepath to save the cropped raster to, the cropped raster is then read back in and returned.\n",
    "    \"\"\"    \n",
    "    ## As crop accepts an iterable of geoms we first put any single geoms into a list\n",
    "    if not isinstance(geoms, Iterable):\n",
    "        geoms = [geoms]\n",
    "\n",
    "    ## Next we crop the image\n",
    "    raster_crop, raster_crop_meta = es.crop_image(raster, geoms)\n",
    "\n",
    "    ## We now need to update the metadata with the spatial data\n",
    "    raster_crop_meta.update({'transform': raster_crop_meta['transform'],\n",
    "                             'height': raster_crop.shape[1],\n",
    "                             'width': raster_crop.shape[2],\n",
    "                             'nodata': raster_crop.min()}) # <- This is the 'mask' value\n",
    "    \n",
    "    with rio.open(outpath, 'w', **raster_crop_meta) as file:\n",
    "        file.write(raster_crop[0], 1)\n",
    "        \n",
    "    raster_crop = rio.open(outpath)\n",
    "    \n",
    "    return raster_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter sites for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter sites and dates for those with scenes\n",
    "dll = sites[(sites['l8_display_id'].notna())|(sites['l7_display_id'].notna())]\n",
    "\n",
    "### Filter sites for those with geometry\n",
    "dll = dll[dll.geometry_poly.notna()].set_geometry('geometry_poly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set download directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Users\\\\User\\\\University College London\\\\O'Sullivan, Aidan - SDG6\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/User/University College London/O'Sullivan, Aidan - SDG6/\")\n",
    "c1_path = \"./Landsat data/Cropped level 1 data/\"\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flag already downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_files = os.listdir(c1_path)\n",
    "\n",
    "dll['downloaded'] = pd.Series(np.bool)\n",
    "\n",
    "for sid in dll.index.get_level_values(0).unique():\n",
    "                 \n",
    "    sid_files = [ i for i in dl_files if sid in i ]\n",
    "    \n",
    "    sitedl = dll.loc[sid,:]\n",
    "    \n",
    "    if len([ i for i in sid_files if 'BQA' in i ])<len(sitedl):\n",
    "        dll.loc[sid,'downloaded'] = False\n",
    "    else:\n",
    "        dll.loc[sid,'downloaded'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dll2 = dll[dll.index.get_level_values(0)=='ATSE20501000']\n",
    "len(dll2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open crop and save rasters from Google open API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0045"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 500m in degrees\n",
    "360*500/(40000*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"1\" value=\"1\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">1/1</span>\n",
       "<span class=\"Time-label\">[04:04<04:04, 244.16s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [████████████████████████████████████████████████████████████] 1/1 [04:04<04:04, 244.16s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## list for exceptions\n",
    "crop_exceptions = [pd.read_csv('./Landsat data/crop_exceptions.csv')]\n",
    "source_exceptions = [pd.read_csv('./Landsat data/source_exceptions.csv')]\n",
    "meta_exceptions = [pd.read_csv('./Landsat data/meta_exceptions.csv')]\n",
    "\n",
    "for sid in track(dll2.index.get_level_values(0).unique()): #[dll2.downloaded==False]\n",
    "    \n",
    "    ## subset site list for site\n",
    "    sitedl = dll2.loc[sid,:]\n",
    "    \n",
    "    ## setup polygon for cropping\n",
    "    polygon_bbox = gp.GeoDataFrame(gp.GeoSeries(sitedl.envelope), columns=['geometry'],crs=sitedl.crs)\n",
    "    polygon_bbox = polygon_bbox.buffer(0.005)\n",
    "\n",
    "    ### Create scene entity lists\n",
    "    dsids = list(sitedl[sitedl.l7_display_id.notna()].l7_display_id)\n",
    "    dsids += list(sitedl[sitedl.l8_display_id.notna()].l8_display_id)\n",
    "\n",
    "    #dsids_5 = [ i for i in sitedl.l5_display_id if 'LT05' in i]\n",
    "    dsids_7 = [ i for i in dsids if 'LE07' in i]\n",
    "    dsids_8 = [ i for i in dsids if 'LC08' in i]\n",
    "    \n",
    "    #~~~~~~~~download raster bands~~~~~~~~~~~#\n",
    "    \n",
    "    ## site id\n",
    "    site_id = sid\n",
    "    \n",
    "    ## create bands list\n",
    "    #bands_5 = ['B1','B2','B3','B4','B5','BQA','B6']\n",
    "    bands_7 = ['B1','B2','B3','B4','B5','BQA','B6_VCID_1','B6_VCID_2']\n",
    "    bands_8 = ['B2','B3','B4','B5','BQA','B10','B11']\n",
    "\n",
    "    ## create iterate list\n",
    "    #zip_list = list(zip(sorted(bands_5*len(dsids_5)),dsids_5*len(bands_5)))\n",
    "    zip_list = list(zip(sorted(bands_7*len(dsids_7)),dsids_7*len(bands_7)))\n",
    "    zip_list += list(zip(sorted(bands_8*len(dsids_8)),dsids_8*len(bands_8)))\n",
    "\n",
    "    for band,dsid in zip_list:\n",
    "\n",
    "        ## create url elements\n",
    "        displayid = dsid\n",
    "        platform = dsid[0:4]\n",
    "        key = dsid[10:13]+'/'+dsid[13:16]\n",
    "\n",
    "        ## TIF construct source url\n",
    "        filepath = f'https://storage.googleapis.com/gcp-public-data-landsat/{platform}/01/{key}/{dsid}/{dsid}_{band}.TIF'\n",
    "\n",
    "        try:\n",
    "\n",
    "            with rio.open(filepath) as src:\n",
    "\n",
    "                polygon_bbox = polygon_bbox.to_crs(src.crs)\n",
    "                polygon_geom = polygon_bbox.geometry\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    cropped = cropper(src, polygon_geom, c1_path+site_id+'__'+dsid+'_'+band+'.TIF')\n",
    "\n",
    "                except:\n",
    "                    crop_exceptions.append(dsid+band)\n",
    "                    print(f'Crop exception for {dsid} {band}')\n",
    "                    \n",
    "\n",
    "                src.close()\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "        except:\n",
    "            source_exceptions.append(dsid+band)\n",
    "            print(f'Source exception for {dsid} {band}')\n",
    "            print(filepath)\n",
    "\n",
    "    \n",
    "    #~~~~~~~~download meta data~~~~~~~~~~~#        \n",
    "            \n",
    "    meta_file_7 = ['MTL','ANG','GCP']\n",
    "    meta_file_8 = ['MTL','ANG']\n",
    "    \n",
    "    ## create iterate list\n",
    "    #zip_list = list(zip(sorted(bands_5*len(dsids_5)),dsids_5*len(bands_5)))\n",
    "    zip_list = list(zip(sorted(meta_file_7*len(dsids_7)),dsids_7*len(bands_7)))\n",
    "    zip_list += list(zip(sorted(meta_file_8*len(dsids_8)),dsids_8*len(bands_8)))\n",
    "\n",
    "    \n",
    "    for mf,dsid in zip_list:\n",
    "\n",
    "        ## create url elements\n",
    "        displayid = dsid\n",
    "        platform = dsid[0:4]\n",
    "        key = dsid[10:13]+'/'+dsid[13:16]\n",
    "\n",
    "        ## Metadata construct source url\n",
    "        filepath = f'https://storage.googleapis.com/gcp-public-data-landsat/{platform}/01/{key}/{dsid}/{dsid}_{mf}.txt'\n",
    "\n",
    "        try:\n",
    "\n",
    "            ## MTL file\n",
    "            remote_file = urllib.request.urlopen(filepath).read()\n",
    "\n",
    "            local_file = open(c1_path+dsid+'_'+mf+'.txt','wb')\n",
    "            local_file.write(remote_file)\n",
    "            local_file.close()\n",
    "\n",
    "        except:\n",
    "            meta_exceptions.append(dsid)\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            print(f'Scene meta not available {dsid}')\n",
    "            \n",
    "pd.Series(meta_exceptions).to_csv('./Landsat data/meta_exceptions.csv')\n",
    "pd.Series(crop_exceptions).to_csv('./Landsat data/crop_exceptions.csv')\n",
    "pd.Series(source_exceptions).to_csv('./Landsat data/source_exceptions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><span class=\"Text-label\" style=\"display:inline-block; overflow:hidden; white-space:nowrap; text-overflow:ellipsis; min-width:0; max-width:15ex; vertical-align:middle; text-align:right\"></span>\n",
       "<progress style=\"width:60ex\" max=\"2\" value=\"2\" class=\"Progress-main\"/></progress>\n",
       "<span class=\"Progress-label\"><strong>100%</strong></span>\n",
       "<span class=\"Iteration-label\">2/2</span>\n",
       "<span class=\"Time-label\">[00:05<00:01, 2.40s/it]</span></div>"
      ],
      "text/plain": [
       "\u001b[A\u001b[2K\r",
       " [████████████████████████████████████████████████████████████] 2/2 [00:05<00:01, 2.40s/it]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## list for exceptions\n",
    "meta_exceptions = ['Meta file not downloaded']\n",
    "\n",
    "meta_file_7 = ['MTL','ANG','GCP']\n",
    "meta_file_8 = ['MTL','ANG']\n",
    "\n",
    "for sid in track(dll2.index.get_level_values(0)): #[dll2.downloaded==False]\n",
    "    \n",
    "    sitedl = dll2.loc[sid,:]\n",
    "    \n",
    "    ### Create scene entity lists\n",
    "    dsids = list(sitedl[sitedl.l7_display_id.notna()].l7_display_id)\n",
    "    dsids += list(sitedl[sitedl.l8_display_id.notna()].l8_display_id)\n",
    "    \n",
    "    #dsids_5 = [ i for i in sitedl.l5_display_id if 'LT05' in i]\n",
    "    dsids_7 = [ i for i in dsids if 'LE07' in i]\n",
    "    dsids_8 = [ i for i in dsids if 'LC08' in i]\n",
    "    \n",
    "    ## create iterate list\n",
    "    #zip_list = list(zip(sorted(bands_5*len(dsids_5)),dsids_5*len(bands_5)))\n",
    "    zip_list = list(zip(sorted(meta_file_7*len(dsids_7)),dsids_7*len(meta_file_7)))\n",
    "    zip_list += list(zip(sorted(meta_file_8*len(dsids_8)),dsids_8*len(meta_file_8)))\n",
    "\n",
    "    for mf,dsid in zip_list:\n",
    "\n",
    "        ## create url elements\n",
    "        displayid = dsid\n",
    "        platform = dsid[0:4]\n",
    "        key = dsid[10:13]+'/'+dsid[13:16]\n",
    "\n",
    "        ## Metadata construct source url\n",
    "        filepath = f'https://storage.googleapis.com/gcp-public-data-landsat/{platform}/01/{key}/{dsid}/{dsid}_{mf}.txt'\n",
    "        \n",
    "        try:\n",
    "\n",
    "            ## MTL file\n",
    "            remote_file = urllib.request.urlopen(filepath).read()\n",
    "\n",
    "            local_file = open(c1_path+dsid+'_'+mf+'.txt','wb')\n",
    "            local_file.write(remote_file)\n",
    "            local_file.close()\n",
    "\n",
    "        except:\n",
    "            meta_exceptions.append(dsid)\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            print(f'Scene meta not available {dsid}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
